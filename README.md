# Awesome Autonomous Vehicles: 
[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
精选无人能驾驶资源列表，修改自[takeitallsource/awesome-autonomous-vehicles](https://github.com/takeitallsource/awesome-autonomous-vehicles) :fire:. 

> 除此之外，将继续跟随最新资源，大家多多关注~~~

## 贡献

希望大家自由给列表进行pull request~~

## Table of Contents
* [基础](#基础)
* [课程](#课程)
* [研究实验室](#研究实验室)
* [数据集](#数据集)
* [开源软件](#开源软件)
* [硬件](#硬件)
* [小游戏](#小游戏)
* [公司](#公司)
* [媒体](#媒体)
* [法规](#法规)


## 基础

### 人工智能|Artificial Intelligence

* [GitHub: Awesome Machine Learning](https://github.com/josephmisiti/awesome-machine-learning) :star:38.8K - `机器学习`框架、库和软件的`精选列表`。 由Joseph Misiti.Joseph Misiti维护
* [GitHub: Deep Learning Papers Reading Roadmap](https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap) :star:22.2K - `深度学习论文阅读路线图`从大纲到细节构建，从最新到最先进，从通用到特定领域，重点关注从深度学习开始的SOTA技术。 由Flood Sung维护。
* [Web: Open Source Deep Learning Curriculum](http://www.deeplearningweekly.com/pages/open_source_deep_learning_curriculum)  - `深度学习课程`旨在成为每个有兴趣认真学习该领域的人的起点。

### 机器人学|Robotics
* [GitHub: Awesome Robotics](https://github.com/Kiloreux/awesome-robotics) :star:1.19K - 由kiloreux维护的机器人技术的各种书籍，课程和其他资源的列表。

### 计算机视觉|Computer Vision
* [Awesome Computer Vision](https://github.com/jbhuang0604/awesome-computer-vision) :star: 9.7K (4年前更新)- 计算机视觉资源精选清单
* [Awesome Deep Vision](https://github.com/kjw0612/awesome-deep-vision) :star:7.9K(2年前更新) - 计算机视觉深度学习资源的精选清单

## 课程
* [[优达学城] Self-Driving Car Nanodegree Program](https://www.udacity.com/course/self-driving-car-engineer-nanodegree--nd013) - 教学自动驾驶团队使用的技能和技巧。 可以在[这里](https://medium.com/self-driving-cars/term-1-in-depth-on-udacitys-self-driving-car-curriculum-ffcf46af0c08#.bfgw9uxd9)找到课程大纲 .
* [[多伦多大学] CSC2541 Visual Perception for Autonomous Driving](http://www.cs.toronto.edu/~urtasun/courses/CSC2541/CSC2541_Winter16.html) - 自动驾驶视觉感知研究生课程。 本课程简要介绍了定位，自我运动估计，自由空间估计，视觉识别（分类，检测，分割）等主题。
* [[INRIA] Mobile Robots and Autonomous Vehicles](https://www.fun-mooc.fr/courses/inria/41005S02/session02/about?utm_source=mooc-list) - 介绍了对移动机器人和自动驾驶汽车进行编程所需的关键概念。 该课程提供了算法工具，并针对其上周的主题（行为建模和学习），它还将提供Python中的实际示例和编程练习。
* [[格拉斯哥大学] ENG5017 Autonomous Vehicle Guidance Systems](http://www.gla.ac.uk/coursecatalogue/course/?code=ENG5017)  - 介绍自动驾驶仪指导和协调背后的概念，使学生能够设计和实施规划、优化和反应的车辆的指导策略。
* [[David Silver - 优达学城] How to Land An Autonomous Vehicle Job: Coursework](https://medium.com/self-driving-cars/how-to-land-an-autonomous-vehicle-job-coursework-e7acc2bfe740#.j5b2kwbso) - 来自Udacity的David Silver回顾了他在软件工程背景下从事自动驾驶汽车工作的课程。
* [[斯坦福] - CS221 Artificial Intelligence: Principles and Techniques](http://stanford.edu/~cpiech/cs221/index.html)  - 包含一个简单的自动驾驶项目以及模拟器。
* [[MIT] 6.S094: Deep Learning for Self-Driving Cars](http://selfdrivingcars.mit.edu/)  - 通过构建自动驾驶汽车的应用主题介绍深度学习的实践。
* [[MIT] 2.166 Duckietown](http://duckietown.mit.edu/index.html)  - 关于研究生水平的自动化科学课程。 这是一个实践性的，以项目为中心的课程，侧重于自动驾驶车辆和高级自动化。 问题：**为Duckietown（小鸭城）设计自动机器人出租车系统。**



## 研究实验室
### 高校
#### 国外高校（不分先后）
##### 美国
* 斯坦福大学|Stanford University
    * [Center for Automotive Research at Stanford](https://cars.stanford.edu/) - 目前的研究领域侧重于以人为中心的流动性主题，例如了解人们如何与日益自动化的车辆互动，车辆自动化从政策到伦理到法律的社会影响，传感，决策和控制方面的技术进步。
    * [SAIL-TOYOTA Center for AI Research at Stanford](http://aicenter.stanford.edu/research/)  - 该中心的主题是**以人为本的人工智能，用于未来的智能车辆及其他。**
    * [ASL:Autonomous System lab](http://asl.stanford.edu/) - 设计和控制的方法，特别强调大型机器人网络和自主航空航天器。 该实验室结合了控制理论、机器人技术、优化和运筹学方面的专业知识，为在不确定、快速变化和潜在对抗环境中运行的网络化自治系统开发理论基础。
    * [SISL:Stanford Intelligent System Laboratory](http://web.stanford.edu/group/sisl/cgi-bin/wordpress/) - 斯坦福人工智能实验室 主要关注于稳健决策系统的先进算法和分析方法。在无人驾驶的最新研究在[这里](http://web.stanford.edu/group/sisl/cgi-bin/wordpress/research/),
    侧重于建模、感知和规划。
* 卡内基梅陇大学|Carnegie Mellon University
    * [CMU The Robotic Institute](https://www.ri.cmu.edu/) - - 从事计算机视觉，自主导航，虚拟现实，智能操纵，空间机器人和相关领域的工作。
        * [The Carnegie Mellon University Navigation Laboratory](https://www.cs.cmu.edu/afs/cs/project/alv/www/) - CMU Navlab小组主要研究自动驾驶和辅助驾驶控制的车辆。
* 麻省理工学院|MIT
    * [CSAIL:Computer Science and Artificial Intelligence Laboratory](https://www.csail.mit.edu/) - MIT 计算机科学和人工智能实验室开创了计算领域的研究。
        * [Toyota-CSAIL Research Center at MIT](http://toyota.csail.mit.edu/) - 旨在进一步发展自动驾驶汽车技术，目标是减少交通伤亡，甚至可能开发无法发生事故的车辆。
        * [LIS：Learning and Intelligent System](http://lis.csail.mit.edu/new/) -  研究汇集了来自运动和任务规划，机器学习，强化学习和计算机视觉的想法，以综合能够在各种问题领域中智能地运行的机器人系统。
        * [Robust Robotics Group](https://groups.csail.mit.edu/rrg/) - 在决策理论规划，统计推断和人工智能方面的算法优化。 特别关注具有不确定模型的领域中的规划和控制问题，使用优化，统计估计和机器学习来从经验中学习良好的计划和策略。
        * [Interactive Robotics Group](https://interactive.mit.edu/) - 设计机器智能来增强人的能力
    * [LIDS:Laboratory for Information & Decision Systems](https://lids.mit.edu/) - 研究中心，致力于推进分析信息和决策科学的研究和教育，特别是：系统和控制通信、网络推理和统计数据处理。
        * [ACL:Aerospace Control Lab](https://lids.mit.edu/labs-and-groups/aerospace-controls-laboratory-acl) - 不确定性下的决策; 路径规划，活动和任务分配; 估计和导航; 传感器网络设计; 鲁棒控制，自适应控制和模型预测控制。
* 波斯顿大学|Boston University
* 伯克利|University of California, Berkeley
    * [Berkeley DeepDrive](http://bdd.berkeley.edu/)  - 研究汽车应用的计算机视觉和机器学习方面的最新技术。
    * [MSC:Mechanical Systems Control Laboratory](https://msc.berkeley.edu/) - 无人驾驶相关上，专注于提出新颖的方法和建立相应的设施，以解决全堆栈自动驾驶中最具挑战性的实际问题。 我们将传统控制，规划和状态估计方法（最优/鲁棒控制，优化，图搜索，贝叶斯过滤等）与最先进的机器学习方法（强化学习，深度神经网络，概率图形模型， 等）结合。
    * [MPC Lab Research](https://automatedcars.space/)  - 过去十年，MPC lab一直专注于先进的汽车安全系统,开发一种新的科学网络物理系统科学，其目标是获得一个可证明安全的以人为中心的自治权。
    * [BAIR:Berkeley AI Research Lab](https://bair.berkeley.edu/) - 致力于研究 计算机视觉、机器学习、NLP、规划和机器人学。
        * [InterACT](http://interact.berkeley.edu/) - 人机交互、机器人 控制、规划、评估、学习以及认知科学
    * [AUTOLAB](http://autolab.berkeley.edu/) - 机器人和自动化方面
    
* 普林斯顿|Princeton University
    * [Princeton Autonomous Vehicle Engineering](http://pave.princeton.edu/) - 普林斯顿大学以本科生为主导的研究小组，致力于通过竞争挑战，自我引导研究和社区外展推动和推动机器人领域。
    * [Princeton Vision & Robotics](http://vision.princeton.edu/research.html)  - 自动驾驶和街景。
* 马里兰大学|University of Maryland
    * [University of Maryland Autonomous Vehicle Laboratory](http://www.avl.umd.edu/)  - 在生物启发设计和机器人领域进行研究和开发。
* 德克萨斯州大学奥斯汀分校|UTEXAS
    * [MSL: Mobility Systems Laboratory](https://sites.utexas.edu/msl/) - 拥有广泛的研究活动，涵盖领域包括动力系统的控制，建模，估算，优化和诊断，特别是发动机，动力总成，后处理，混合动力，灵活燃料，替代/可再生能源，能量存储，（电动）地面车辆，自动驾驶汽车，智能交通，智能和可持续的移动性，以人为中心的自动化，网络物理和机电一体化系统
* 密歇根大学|University of Michigan
    * [Michigan Robotics](https://robotics.umich.edu/) - 密歇根机器人研究所，研究方向有：人工智能、无人驾驶/网联车、机器人深度学习、人机交互、腿部运动和外骨骼、远程操作、运动规划、感知和计算机视觉等。
    * [MCity Driverless Shuttle research](https://mcity.umich.edu/shuttle/)  - LiDAR、GPS、摄像头、WiFi的电动11座巴士解决方案
    * [UMTRI：University of Michigan Transportation Research Institute]
* 康内尔大学|Cornell University
* 芝加哥大学|The University of Chicago
* 加州大学圣地亚哥分校| University of California, San Diego
    * [LISA:Laboratory for Intelligent & Safe Automobiles](http://cvrr.ucsd.edu/) - LISA旨在探索创新方法，使未来的汽车更安全，更“智能”。 我们的研究考虑了与驾驶员，乘员，车辆动力学和车辆环境以及交通基础设施相关的参数的传感，分析，建模和预测问题。团队拥有广泛的理论和实验研究议程。 我们的实验室中有几个独特而强大的试验台，包括车辆，实时机器视觉系统，多模式接口和驾驶模拟器。
* 宾夕法尼亚大学|University of Pennsylvania
    * [GRASP]
        * [Kumar Lab]

##### 加拿大  
* 多伦多大学|University of Toronto
    * [Raquel Urtasun带领 Uber ATG](http://www.cs.utoronto.ca/~urtasun/) - 由Uber ATG首席科学家兼Uber ATG 多伦多负责人带领的Raquel Urtasun，研究领域包括：自动驾驶汽车，计算机视觉，机器学习，遥感和机器人。
    * [Dynamic Systems Lab](http://www.dynsyslab.org/vision-news/) - 计划在未来三年内设计，开发和测试自动驾驶汽车。该团队将会提出无人驾驶汽车的新的解决方案，例如本地化和地图，姿势估计，车道和道路保持以及障碍物检测和跟踪。
* 滑铁卢大学|University of Waterloo
    * [WatCAR:The Waterloo Centre for Automotive Research](https://uwaterloo.ca/centre-automotive-research/) - 致力于汽车和运输系统的合作研究，通过促进汽车行业和滑铁卢大学教授研究人员之间的关系。
    * [CogDrive: Cognitive Autonomous Driving Lab](https://uwaterloo.ca/scholar/dongpu) - 主要研究方向包括驾驶员行为与认知，人车协同，认知自动驾驶等。
    * [University of Waterloo WAVE Laboratory](http://wavelab.uwaterloo.ca/)  - 研究领域包括Multirotor无人机，自动驾驶和多摄像机并行跟踪和绘图。
    * [Mechatronic Vehicle Systems Lab](https://uwaterloo.ca/mechatronic-vehicle-systems-lab/) - 机电一体化车辆系统实验室的任务是应对这些挑战以及与各种控制系统相关的其他挑战，例如牵引力控制，车辆稳定性控制和受控悬架将有助于开发能够生产下一代电动车辆系统的技术。满足对车辆动态性能，主动安全性和环境可持续性的高要求。
  
##### 英国
* 牛津大学|University of Oxford
    * [Oxford Robotics Institute – Autonomous Systems](http://mrg.robots.ox.ac.uk/)  - 研究基于陆地的移动自动化的各个方面。
##### 德国
* 柏林大学|Freie Universität Berlin
    * [Autonomous Lab - Freie Universität Berlin](http://autonomos-labs.com/)  - 计算机视觉，认知导航，空间汽车环境捕获。
* 慕尼黑联邦国防大学|
##### 法国
* 法国国家资讯与自动化研究所
    * [RITS:Robotics and Intelligent Transportation Systems]
##### 瑞士
* 苏黎世联邦理工学院
    * ASL：Autonomous Systems Lab
##### 意大利
* 帕尔马大学
    * VisLab（目前已和安霸合并）
##### 新加坡
* 南洋理工

##### 韩国
##### 日本



#### 国内高校（不分先后）
* 清华大学
    * Lab of Intelligent and Connected Vehicles（李克强 教授带领）
    * iDLAB:Intelligent Driving Laboratory（成波 教授）
* 国防科大
    * 机电工程与自动化学院（贺汉根 教授）
* 西交
    * 人工智能与机器人研究所（郑南宁 院士）
        * Visual Cognitive Computing and Intelligent Vehicle Lab（薛建儒）
* 同济
    * 计算机视觉与遥感研究组
    * 同济智能汽车研究所（余卓平）
* 北理
    * 北理汽车研究所
    * 北理智能车辆研究中心（龚建伟）
* 吉大
    * 汽车工程学院
* 上交
    * 智能交通与无人机应用研究中心（彭仲仁）
* 武大
* 华科
* 湖南大学
* 中科院合肥物质科学学院
* 港科大
    *  Areial Robotics Group(沈邵劼 )
    * 香港科大机器人研究所
### 研究机构
* [Honda Research Institute - USA](http://usa.honda-ri.com/Pages/Research%20Area/Detail.aspx?listId=2) - engaged in development and integration of multiple sensory modules and the coordination of these components while fulfilling tasks such as stable motion planning,  decision making, obstacle avoidance, and control (test).​


## 数据集
* [nuScenes](https://www.nuscenes.org/) - 安波福于2019年3月公开了其数据集，并在[GitHub](https://github.com/nutonomy/nuscenes-devkit)公开教程。数据集拥有从波士顿和新加坡收集的1000个“场景”的信息，包含每个城市环境中都有的最复杂的一些驾驶场景。该数据集由140万张图像、39万次激光雷达扫描和140万个3D人工注释边界框组成，是迄今为止公布的最大的多模态3D AV数据集。
* [H3D - HRI-US](https://usa.honda-ri.com/hdd/introduction/h3d) - 本田研究所于2019年3月发布其无人驾驶方向数据集，相关介绍于[arXiv:1903.01568](https://arxiv.org/abs/1903.01568)介绍。本数据集使用3D LiDAR扫描仪收集的大型全环绕3D多目标检测和跟踪数据集。 其包含160个拥挤且高度互动的交通场景，在27,721帧中共有100万个标记实例。凭借独特的数据集大小，丰富的注释和复杂的场景，H3D聚集在一起，以激发对全环绕3D多目标检测和跟踪的研究。
* [ApolloCar3D] - 该数据集包含5,277个驾驶图像和超过60K的汽车实例，其中每辆汽车都配备了具有绝对模型尺寸和语义标记关键点的行业级3D CAD模型。该数据集比PASCAL3D +和KITTI（现有技术水平）大20倍以上。
* [KITTI Vision Benchmark Suite](http://www.cvlibs.net/datasets/kitti/raw_data.php) - 数据集为使用各种传感器模式，例如高分辨率彩色和灰度立体相机，Velodyne 3D激光扫描仪和高精度GPS/IMU惯性导航系统，在10-100 Hz下进行6小时拍摄的交通场景。
* [Cityscape Dataset](https://www.cityscapes-dataset.com/)  - 专注于对城市街景的语义理解。 大型数据集，包含从50个不同城市的街景中记录的各种立体视频序列，高质量的像素级注释为5000帧，另外还有一组较大的20000个弱注释帧。 因此，数据集比先前的类似尝试大一个数量级。 可以使用带注释的类的详细信息和注释示例。
* [Mapillary Vistas Dataset](https://www.mapillary.com/dataset/vistas?pKey=xyW6a0ZmrJtjLw2iJ71Oqg&lat=20&lng=0&z=1.5)-数据集是一个新颖的大规模街道级图像数据集，包含25,000个高分辨率图像，注释为66个对象类别，另有37个类别的特定于实例的标签。通过使用多边形来描绘单个对象，以精细和细粒度的样式执行注释。
* [CamVid](http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/) -剑桥驾驶标签视频数据库（CamVid）是第一个具有对象类语义标签的视频集合，其中包含元数据。 数据库提供基础事实标签，将每个像素与32个语义类之一相关联。 该数据库解决了对实验数据的需求，以定量评估新兴算法。 虽然大多数视频都使用固定位置的闭路电视风格相机拍摄，但我们的数据是从驾驶汽车的角度拍摄的。 驾驶场景增加了观察对象类的数量和异质性。
* [Caltech数据集](http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/) - 加州理工学院行人数据集包括大约10小时的640x480 30Hz视频，这些视频来自在城市环境中通过常规交通的车辆。 大约250,000个帧（137个近似分钟的长段）共有350,000个边界框和2300个独特的行人被注释。 注释包括边界框和详细遮挡标签之间的时间对应。 更多信息可以在我们的PAMI 2012和CVPR 2009基准测试文件中找到。
* [Comma.ai](https://archive.org/details/comma-dataset) - 7.25小时的高速公路驾驶。 包含10个可变大小的视频片段，以20 Hz的频率录制，相机安装在Acura ILX 2016的挡风玻璃上。与视频平行，还记录了一些测量值，如汽车的速度、加速度、转向角、GPS坐标，陀螺仪角度。 这些测量结果转换为均匀的100 Hz时基。
* [Oxford's Robotic Car](http://robotcar-dataset.robots.ox.ac.uk/) - 超过100次重复对英国牛津的路线进行一年多采集拍摄。 该数据集捕获了许多不同的天气，交通和行人组合，以及建筑和道路工程等长期变化。
* [伯克利BDD100K数据](https://bdd-data.berkeley.edu/) - 超过100K的视频和各种注释组成，包括图像级别标记，对象边界框，可行驶区域，车道标记和全帧实例分割，该数据集具有地理，环境和天气多样性
* [Udacity](https://github.com/udacity/self-driving-car/tree/master/datasets) - 为[Udacity Challenges](https://www.udacity.com/self-driving-car)发布的Udacity数据集。 包含ROSBAG训练数据。 （大约80 GB）。
* [University of Michigan North Campus Long-Term Vision and LIDAR Dataset](http://robots.engin.umich.edu/nclt/) -  包括全方位图像，3D激光雷达，平面激光雷达，GPS和本体感应传感器，用于使用Segway机器人收集的测距。
* [University of Michigan Ford Campus Vision and Lidar Data Set](http://robots.engin.umich.edu/SoftwareData/Ford)  - 基于改进的福特F-250皮卡车的自动地面车辆测试台收集的数据集。 该车配备了专业（Applanix POS LV）和消费者（Xsens MTI-G）惯性测量单元（IMU），Velodyne 3D激光雷达扫描仪，两个推扫式前视Riegl激光雷达和Point Grey Ladybug3全方位摄像头 系统。
* [DIPLECS Autonomous Driving Datasets (2015)](http://cvssp.org/data/diplecs/)  - 通过在Surrey乡村周围驾驶的汽车中放置高清摄像头来记录数据集。 该数据集包含大约30分钟的驾驶时间。 视频为1920x1080，采用H.264编解码器编码。 通过跟踪方向盘上的标记来估计转向。 汽车的速度是从汽车的速度表OCR估算的（但不保证方法的准确性）。
* [Velodyne SLAM Dataset from Karlsruhe Institute of Technology](http://www.mrt.kit.edu/z/publ/download/velodyneslam/dataset.html)  - 在德国卡尔斯鲁厄市使用Velodyne HDL64E-S2扫描仪记录的两个具有挑战性的数据集。
* [SYNTHetic collection of Imagery and Annotations (SYNTHIA)](http://synthia-dataset.net/)  - 包括从虚拟城市渲染的照片般逼真的帧集合，并为13个类别提供精确的像素级语义注释：misc，天空，建筑，道路，人行道，围栏，植被，杆，汽车，标志，行人， 骑自行车的人，车道标记。
* [CSSAD Dataset](http://aplicaciones.cimat.mx/Personal/jbhayet/ccsad-dataset)  - 包括若干真实世界的立体数据集，用于在自动驾驶车辆的感知和导航领域中开发和测试算法。 然而，它们都没有记录在发展中国家，因此它们缺乏在街道和道路上可以找到的特殊特征，如丰富的坑洼，减速器和特殊的行人流。 该立体数据集是从移动的车辆记录的，并且包含高分辨率立体图像，其补充有从IMU，GPS数据和来自汽车计算机的数据获得的定向和加速度数据。
* [Daimler Urban Segmetation Dataset](http://www.6d-vision.com/scene-labeling)  - 包括城市交通中记录的视频序列。 该数据集由5000个经过校正的立体图像对组成，分辨率为1024x440。 500帧（序列的每10帧）带有5个类的像素级语义类注释：地面，建筑，车辆，行人，天空。 提供密集视差图作为参考，但是这些不是手动注释的，而是使用半全局匹配（sgm）计算的。
* [Self Racing Cars - XSens/Fairchild Dataset](http://data.selfracingcars.com/)  - 文件包括来自Fairchild FIS1100 6自由度（DoF）IMU，Fairchild FMT-1030 AHRS，Xsens MTi-3 AHRS和Xsens MTi-G-710 GNSS / INS的测量结果。 事件中的文件都可以在MT Manager软件中读取，该软件可作为MT软件套件的一部分提供，可在此处获得。
* [MIT AGE Lab](http://lexfridman.com/automated-synchronization-of-driving-data-video-audio-telemetry-accelerometer/)  -  由AgeLab收集的1,000多小时多传感器驾驶数据集的一小部分样本。
* [LaRA](http://www.lara.prd.fr/lara) -巴黎的交通信号灯数据集
* [KUL Belgium Traffic Sign Dataset](http://www.vision.ee.ethz.ch/~timofter/traffic_signs/)  - 具有10000多个交通标志注释的大型数据集，数千个物理上不同的交通标志。 用8个高分辨率摄像头录制的4个视频序列安装在一辆面包车上，总计超过3个小时，带有交通标志注释，摄像机校准和姿势。 大约16000张背景图片。 这些材料通过GeoAutomation在比利时，佛兰德斯地区的城市环境中捕获。
* [博世小交通灯](https://hci.iwr.uni-heidelberg.de/node/6132) - 用于深度学习的小型交通灯的数据集。
* [LISA: Laboratory for Intelligent & Safe Automobiles, UC San Diego Datasets](http://cvrr.ucsd.edu/LISA/datasets.html)  - 交通标志，车辆检测，交通灯，轨迹模式。
* [Multisensory Omni-directional Long-term Place Recognition (MOLP) dataset for autonomous driving](http://hcr.mines.edu/code/MOLP.html) - 它是在美国科罗拉多州的一年内使用全向立体相机录制的。[论文](https://arxiv.org/abs/1704.05215)
* [DeepTesla](https://selfdrivingcars.mit.edu/deeptesla/) - 主要包括tesla在两种不同驾驶模式（human driving和autopilot）下的前置相机录制的视频和车辆的转向控制信号。数据可以从这里下载:[百度云](https://pan.baidu.com/s/1c2J2IFA#list/path=%2F)。可以参考此[GitHub](https://github.com/CJHMPower/deep-tesla)

## 开源软件
* [Autoware](https://github.com/CPFL/Autoware)  - 用于城市自动驾驶的集成开源软件。
* [Comma.ai Openpilot](https://github.com/commaai/openpilot)  - 开源驱动代理。
* [Stanford Driving Software](https://sourceforge.net/projects/stanforddriving/)  - 斯坦福自动驾驶汽车的软件基础设施。
* [GTA Robotics SDC Environment](https://github.com/OSSDC/self-driving-car-1)  - 为Udacity无人驾驶车（SDC）挑战做好准备的开发环境。
* [The OSCC Project](http://oscc.io/)  - 用于自动驾驶汽车开发的线控控制套件。
## 硬件


## 小游戏
* [TensorKart](https://github.com/kevinhughes27/TensorKart)  - 使用TensorFlow搭建的自驾驾驶MarioKart。
* [NeuroJS](https://github.com/janhuenermann/neurojs)  - javascript深度学习和强化学习库。 一个样本自动驾驶汽车实施。
* [Metacar](https://github.com/thibo73800/metacar) - 仅需通过浏览器就可以进行训练，为自动驾驶汽车提供强化学习环境。
* [DeepTraffic](https://github.com/lexfridman/deeptraffic) - 作为MIT深度学习课程的一部分, 作为认知深度强化学习小游戏。仅需通过浏览器设置参数就可以进行训练和评估。

## 公司

* [33 Corporations Working On Autonomous Vehicles](https://www.cbinsights.com/blog/autonomous-driverless-vehicles-corporations-list/)

## 媒体
媒体来源，可以找到自动驾驶相关的主题、想法等等。

#### Youtube
* 视频：自动驾驶的三大支柱。 [[观看](https://www.youtube.com/watch?v=GZa9SlMHhQc)]
* 视频：什么是自动驾驶感应？ [[观看](https://www.youtube.com/watch?v=GCMXXXmxG-I)]
* Amnon Shashua CVPR 2016主题演讲：自动驾驶，计算机视觉和机器学习。 [[观看](https://www.youtube.com/watch?v=n8T7A3wqH3Q)]
* Chris Urmson: 无人驾驶车如何看到这条路。 [[观看](https://www.youtube.com/watch?v=tiwVMrTLUWg)]
* 深入强化学习驾驶政策。 [[观看](https://www.youtube.com/watch?v=cYTVXfIH0MU)]
* 2016年国际消费电子展上的NVIDIA  - 自动驾驶车和深度学习GPU。[[观看](https://www.youtube.com/watch?v=KkpxA5rXjmA)]
* NVIDIA Drive PX2自动驾驶汽车平台可视化。 [[观看](https://www.youtube.com/watch?v=URmxzxYlmtg&app=desktop)]

#### 博客
* [Deep Learning and Autonomous Driving](https://handong1587.github.io/deep_learning/2015/10/09/dl-and-autonomous-driving.html)
* [[Medium] Self-Driving Cars](https://medium.com/self-driving-cars)

#### 知乎
#### 微信公众号

#### 推特
* [comma.ai](https://twitter.com/comma_ai)
* [[Udacity] David Silver](https://twitter.com/dsilver829)
* [[Udacity] Dhruv Parthasarathy](https://twitter.com/dhruvp)
* [[Udacity] Eric Gonzalez](https://twitter.com/ericrgon)
* [[Udacity] Oliver Cameron](https://twitter.com/olivercameron)
* [[Udacity] MacCallister Higgins](https://twitter.com/macjshiggins)
* [[Udacity] Sebastian Thrun](https://twitter.com/SebastianThrun)
* [[Google] Chris Urmson](https://twitter.com/chris_urmson)


## 法规

美国
* [California Regulatory Notice](https://www.dmv.ca.gov/portal/dmv/detail/vr/autonomous/testing)
* [Michigan Just Passed the Most Permissive Self-Driving Car Laws in the Country](http://fortune.com/2016/12/09/michigan-self-driving-cars/)
* [Car accidents involving a SDC in California](https://www.dmv.ca.gov/portal/dmv/detail/vr/autonomous/autonomousveh_ol316)
* [Nvidia starts testing its self-driving cars on public roads](http://www.theinquirer.net/inquirer/news/2479432/nvidia-starts-testing-its-self-driving-cars-on-public-roads)
